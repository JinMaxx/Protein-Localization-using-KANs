{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"table-of-contents\"></a>\n",
    "# Protein Localization Prediction using Kolmogorov-Arnold Networks.\n",
    "Github: https://github.com/JinMaxx/Protein-Localization-using-KANs<br>\n",
    "For optimal performance, please use a GPU runtime T4 or better.\n",
    "\n",
    "## Table of Contents\n",
    "- [01. Install pip Dependencies (Must Execute)](#1-install-pip-dependencies-must-execute)\n",
    "- [02. Check Files (Must Execute)](#2-check-files-must-execute)\n",
    "- [03. Settings (Must execute)](#3-settings-must-execute)\n",
    "- [04. Create Encodings (Must execute)](#4-create-encodings-must-execute)\n",
    "- [05. Visualize Data](#5-visualize-data)\n",
    "- [06. Train Model](#6-train-model)\n",
    "- [07. Continue Training a Saved Model](#7-continue-training-a-saved-model)\n",
    "- [08. Model Comparison](#8-model-comparison)\n",
    "- [09. Explore Figures](#9-explore-figures)\n",
    "\n",
    "---\n",
    "\n",
    "License: MIT<br>\n",
    "This notebook and its code are made available under the MIT License.<br>\n",
    "See [https://opensource.org/licenses/MIT](https://opensource.org/licenses/MIT) for details.<br>\n",
    "\n",
    "---"
   ],
   "id": "d08ba5ed85a7db5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"1-install-pip-dependencies-must-execute\"></a>\n",
    "### 1. Install pip Dependencies (Must Execute)\n",
    "#### [↑](#table-of-contents) [→](#2-check-files-must-execute)"
   ],
   "id": "d4ebe25907c58584"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# !git clone https://github.com/JinMaxx/Protein-Localization-using-KANs.git /content/project_root\n",
    "\n",
    "__repo_url = \"https://github.com/JinMaxx/Protein-Localization-using-KANs.git\"\n",
    "_encodings_download_url = \"YOUR_DIRECT_DOWNLOAD_URL\"\n",
    "_project_root_path = \"/content/project_root\"\n",
    "__branch = \"main\"\n",
    "\n",
    "# 1. Create project_root and initialize an empty Git repo\n",
    "print(\"Initializing Git repository...\")\n",
    "!mkdir -p {_project_root_path}\n",
    "!cd {_project_root_path} && git init -q\n",
    "\n",
    "# 2. Add the remote repository and enable sparse checkout\n",
    "!cd {_project_root_path} && git remote add origin {__repo_url}\n",
    "!cd {_project_root_path} && git config core.sparseCheckout true\n",
    "\n",
    "# 3. Define the files and directories needed\n",
    "print(\"Defining sparse-checkout patterns...\")\n",
    "!echo \"config.yaml\" > {_project_root_path}/.git/info/sparse-checkout\n",
    "!echo \".env\" >> {_project_root_path}/.git/info/sparse-checkout\n",
    "!echo \"source/\" >> {_project_root_path}/.git/info/sparse-checkout\n",
    "!echo \"data/fasta/\" >> {_project_root_path}/.git/info/sparse-checkout\n",
    "\n",
    "# 4. Pull the data from the repository\n",
    "# --depth=1 creates a shallow clone, fetching only the latest commit, saving time and space.\n",
    "print(f\"Fetching from remote repository (__branch: {__branch})...\")\n",
    "!cd {_project_root_path} && git pull --depth=1 origin {__branch}\n",
    "\n",
    "# 5. Verify the contents of your project directory\n",
    "print(\"\\n--- Verification ---\")\n",
    "print(f\"Contents of '{_project_root_path}':\")\n",
    "!ls -l {_project_root_path}\n",
    "\n",
    "# This check ensures the ls command doesn't fail if the source or data/fasta directory for some reason wasn't checked out\n",
    "print(f\"\\nContents of '{_project_root_path}/source':\")\n",
    "!if [ -d \"{_project_root_path}/source\" ]; then ls -l {_project_root_path}/source; else echo \"Source directory not found.\"; fi\n",
    "print(f\"\\nContents of '{_project_root_path}/data/fasta':\")\n",
    "!if [ -d \"{_project_root_path}/data/fasta\" ]; then ls -l {_project_root_path}/data/fasta; else echo \"data/fasta directory not found.\"; fi\n",
    "\n",
    "\n",
    "!pip install -q \\\n",
    "    pypdf \\\n",
    "    optuna \\\n",
    "    dotenv \\\n",
    "    pyfaidx \\\n",
    "    colorcet \\\n",
    "    reportlab \\\n",
    "    biopython \\\n",
    "    umap_learn \\\n",
    "    transformers \\\n",
    "    sentencepiece \\\n",
    "    kaleido==0.2.1 \\\n",
    "    plotly==5.5.0 \\\n",
    "    \"huggingface_hub[hf_xet]\"  # to ignore missing account warnings\n",
    "\n",
    "!pip install git+https://github.com/AthanasiosDelis/faster-kan.git@3bcabc25c1ed5bceb04d58a8c73756a9fe54e81b\n",
    "# !pip install git+https://github.com/ZiyaoLi/fast-kan.git@17b65401c252334fffb5e63c9852dd8316d29e69\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "__cell1 = True"
   ],
   "id": "ac3b59b339f0d1ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"2-check-files-must-execute\"></a>\n",
    "### 2. Check Files (Must Execute)\n",
    "#### [←](#1-install-pip-dependencies-must-execute) [↑](#table-of-contents) [→](#3-settings-must-execute)"
   ],
   "id": "33705631b3ecdc49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell1' in globals(), \"You must execute cell 1 before!\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sysconfig\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "# The root path of the project is the directory of the cloned the project repository\n",
    "os.chdir(_project_root_path)\n",
    "if _project_root_path not in sys.path:\n",
    "    sys.path.append(_project_root_path)\n",
    "\n",
    "# --- Environment Variables ---\n",
    "__dotenv_path = os.path.join(_project_root_path, \".env\")\n",
    "if os.path.exists(__dotenv_path):\n",
    "    load_dotenv(dotenv_path=__dotenv_path)\n",
    "    print(\"Successfully loaded environment variables from .env file.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\".env file not found in the repository root.\")\n",
    "\n",
    "# For compatibility with subsequent cells, set BASE_COLAB programmatically\n",
    "os.environ['BASE_COLAB'] = _project_root_path\n",
    "\n",
    "\n",
    "# --- GPU Check ---\n",
    "# for google colab checking if running with GPU\n",
    "__gpu_info = !nvidia-smi\n",
    "__gpu_info = '\\n'.join(__gpu_info)\n",
    "if __gpu_info.find('failed') >= 0: print('Not connected to a GPU')\n",
    "else: print(__gpu_info)\n",
    "\n",
    "\n",
    "# --- File Listing (for verification) ---\n",
    "def _list_files(path) -> list[str] | None:\n",
    "    # Check if the folder exists and list files\n",
    "    if os.path.exists(path):\n",
    "        files = os.listdir(path)  # List all files and directories\n",
    "        if files:\n",
    "            print(f\"Files and directories in '{path}':\")\n",
    "            for file in files: print(f\"- {file}\")\n",
    "            return files\n",
    "        else:\n",
    "            print(f\"The folder '{path}' is empty.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"The folder '{path}' does not exist.\")\n",
    "        return None\n",
    "\n",
    "_list_files(_project_root_path)\n",
    "\n",
    "\n",
    "sys.path.append(_project_root_path)  # Project root\n",
    "\n",
    "\n",
    "# --- APPLY PATCHES ---\n",
    "\n",
    "patches_to_apply = [\n",
    "    # {\n",
    "    #     \"target_rel_path\": os.path.join(\"<PACKAGE_DIR_NAME>\", \"<FILE>.py\"),\n",
    "    #     \"patch_file_path\": \"source/patches/<FILE>.patch\",\n",
    "    #     \"description\": \"<PACKAGE> <FILE>.py\"\n",
    "    # },\n",
    "]\n",
    "\n",
    "if patches_to_apply:\n",
    "    print(\"\\n--- Applying patches ---\")\n",
    "\n",
    "    # Find the site-packages directory once\n",
    "    site_packages_path = sysconfig.get_path('purelib')\n",
    "    print(f\"Located site-packages directory at: {site_packages_path}\")\n",
    "\n",
    "    for patch_info in patches_to_apply:\n",
    "        description = patch_info[\"description\"]\n",
    "        target_file = os.path.join(site_packages_path, patch_info[\"target_rel_path\"])\n",
    "        patch_file = patch_info[\"patch_file_path\"]\n",
    "\n",
    "        print(f\"\\nAttempting to patch {description}...\")\n",
    "\n",
    "        # Check that both files exist before attempting the patch\n",
    "        if os.path.exists(target_file) and os.path.exists(patch_file):\n",
    "            print(f\"  - Found target file: {target_file}\")\n",
    "            print(f\"  - Found patch file: {patch_file}\")\n",
    "\n",
    "            # Execute the patch command using shell access\n",
    "            !patch \"{target_file}\" < \"{patch_file}\"\n",
    "\n",
    "            print(f\"  => Patch for {description} applied successfully.\")\n",
    "        else:\n",
    "            print(f\"  => ERROR: Patch for {description} failed.\")\n",
    "            if not os.path.exists(target_file):\n",
    "                print(f\"    - Target file not found at: {target_file}\")\n",
    "            if not os.path.exists(patch_file):\n",
    "                print(f\"    - Patch file not found at: {patch_file}\")\n",
    "\n",
    "    print(\"\\n--- Finished applying all patches ---\")\n",
    "    # --- END OF PATCH SECTION ---\n",
    "\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "__cell2 = True"
   ],
   "id": "fb637a292bac844b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"3-settings-must-execute\"></a>\n",
    "### 3. Settings (Must execute)\n",
    "#### [←](#2-check-files-must-execute) [↑](#table-of-contents) [→](#4-create-encodings-must-execute)"
   ],
   "id": "351de552ef646f21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell2' in globals(), \"You must execute cell 2 before!\"\n",
    "\n",
    "# @markdown Choose a protein language model:\n",
    "encoding_model_name = \"Rostlab/prot_t5_xl_uniref50\" # @param [\"onehot\", \"Rostlab/prot_t5_xl_uniref50\", \"Rostlab/prot_t5_xl_half_uniref50-enc\", \"ElnaggarLab/ankh-base\", \"ElnaggarLab/ankh-large\", \"facebook/esm2_t6_8M_UR50D\", \"facebook/esm2_t12_35M_UR50D\", \"facebook/esm2_t30_150M_UR50D\", \"facebook/esm2_t33_650M_UR50D\"]\n",
    "\n",
    "_fasta_input_dir: str      = os.getenv(\"ENCODINGS_INPUT_DIR_COLAB\")\n",
    "_encodings_output_dir: str = os.path.join(os.getenv('ENCODINGS_OUTPUT_DIR_COLAB'), encoding_model_name)\n",
    "\n",
    "train_file_name = \"deeploc_our_train_set\"  # @param {type:\"string\"}\n",
    "val_file_name   = \"deeploc_our_val_set\"    # @param {type:\"string\"}\n",
    "test_file_name  = \"setHARD\"                # @param {type:\"string\"}\n",
    "                # \"deeploc_test_set\"\n",
    "\n",
    "_train_encodings_file_path = os.path.join(\n",
    "    _encodings_output_dir,\n",
    "    f\"{os.path.splitext(os.path.basename(train_file_name))[0]}.h5\"\n",
    ")\n",
    "_val_encodings_file_path   = os.path.join(\n",
    "    _encodings_output_dir,\n",
    "    f\"{os.path.splitext(os.path.basename(val_file_name))[0]}.h5\"\n",
    ")\n",
    "_test_encodings_file_path  = os.path.join(\n",
    "    _encodings_output_dir,\n",
    "    f\"{os.path.splitext(os.path.basename(test_file_name))[0]}.h5\"\n",
    ")\n",
    "\n",
    "\n",
    "# Setting to more specified subfolders corresponding to encoding model. -> Less confusion and mistakes\n",
    "\n",
    "_model_save_dir: str                = os.path.join(os.getenv(\"MODEL_SAVE_DIR_COLAB\"), encoding_model_name)\n",
    "\n",
    "_figures_save_dir: str              = os.path.join(os.getenv(\"FIGURES_SAVE_DIR_COLAB\"), encoding_model_name)\n",
    "\n",
    "_studies_save_dir: str              = os.path.join(os.getenv(\"STUDIES_SAVE_DIR_COLAB\"), encoding_model_name)\n",
    "\n",
    "_log_file_path: str                 = os.getenv(\"LOG_FILE_PATH_COLAB\")\n",
    "_training_metrics_file_path: str    = os.getenv(\"TRAINING_METRICS_FILE_PATH_COLAB\")\n",
    "_hyper_param_metrics_file_path: str = os.getenv(\"HYPER_PARAM_METRICS_FILE_PATH_COLAB\")\n",
    "_evaluation_metrics_file_path: str  = os.getenv(\"EVALUATION_METRICS_FILE_PATH_COLAB\")\n",
    "\n",
    "_log_file_path = os.path.join(os.path.dirname(_log_file_path), encoding_model_name, os.path.basename(_log_file_path))\n",
    "_training_metrics_file_path = os.path.join(os.path.dirname(_training_metrics_file_path), encoding_model_name, os.path.basename(_training_metrics_file_path))\n",
    "_hyper_param_metrics_file_path = os.path.join(os.path.dirname(_hyper_param_metrics_file_path), encoding_model_name, os.path.basename(_hyper_param_metrics_file_path))\n",
    "\n",
    "\n",
    "print(f\"fasta_input_dir: ............. {_fasta_input_dir}\")\n",
    "if not os.path.isdir(_fasta_input_dir): raise FileNotFoundError(f\"Input directory {_fasta_input_dir} does not exist.\")\n",
    "if not _list_files(_fasta_input_dir): raise FileNotFoundError(f\"Input directory {_fasta_input_dir} is empty.\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"encodings_output_dir: ........ {_encodings_output_dir}\\n\")\n",
    "os.makedirs(_encodings_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"train_encodings_file_path: ... {_train_encodings_file_path}\")\n",
    "print(f\"val_encodings_file_path: ..... {_val_encodings_file_path}\")\n",
    "print(f\"test_encodings_file_path: .... {_test_encodings_file_path}\\n\")\n",
    "\n",
    "print(f\"model_save_dir: .............. {_model_save_dir}\")\n",
    "os.makedirs(_model_save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"figures_save_dir: ............ {_figures_save_dir}\")\n",
    "os.makedirs(_encodings_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"studies_save_dir: ............ {_studies_save_dir}\")\n",
    "os.makedirs(_studies_save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"log_file_path: ............... {_log_file_path}\")\n",
    "print(f\"training_metrics_file_path: .. {_training_metrics_file_path}\")\n",
    "print(f\"hyper_param_metrics_file_path: {_hyper_param_metrics_file_path}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# @markdown Edit config.yaml?\n",
    "edit_config = False  # @param {type:\"boolean\"}\n",
    "\n",
    "__config_file_path = os.getenv(\"CONFIG_PATH_COLAB\")\n",
    "\n",
    "if edit_config:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Markdown\n",
    "\n",
    "    __content: str\n",
    "    with open(__config_file_path, \"r\") as file:\n",
    "        __content = file.read()\n",
    "\n",
    "    __textarea = widgets.Textarea(\n",
    "        value = __content,\n",
    "        layout = widgets.Layout(width='100%', height='400px')\n",
    "    )\n",
    "    __save_button = widgets.Button(description=\"Save\", button_style='success')\n",
    "    __output = widgets.Output()\n",
    "\n",
    "    def save_config(_):\n",
    "        with __output:\n",
    "            # output.clear_output()\n",
    "            try:\n",
    "                with open(__config_file_path, 'w') as file:\n",
    "                    file.write(__textarea.value)\n",
    "                print(\"Configuration saved!\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    __save_button.on_click(save_config)\n",
    "\n",
    "    display(Markdown(\"**Edit your config below:**\"))\n",
    "    display(__textarea)\n",
    "    display(__save_button, __output)\n",
    "\n",
    "else:\n",
    "    from IPython.display import display, Markdown\n",
    "\n",
    "    with open(__config_file_path, \"r\") as file:\n",
    "        __content = file.read()\n",
    "        display(Markdown(f\"```yaml\\n{__content}\\n```\"))\n",
    "\n",
    "\n",
    "__cell3 = True"
   ],
   "id": "d80fc874e78dc958",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"4-create-encodings-must-execute\"></a>\n",
    "### 4. Create Encodings (Must execute)\n",
    "#### [←](#3-settings-must-execute) [↑](#table-of-contents) [→](#5-visualize-data)\n",
    "Pre-computed embeddings for the default datasets, generated using the Rostlab/prot_t5_xl_uniref50 model, are included with this project and are ready to download."
   ],
   "id": "c381f63bf13cae85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell3' in globals(), \"You must execute cell 3 before!\"\n",
    "\n",
    "import time\n",
    "from source.data_scripts.encodings import main as generate_embeddings\n",
    "\n",
    "\n",
    "# @markdown Download preprocessed prot_t5_xl_uniref50 embeddings.\n",
    "download_embeddings = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# @markdown Choose batch size (might impact memory):\n",
    "batch_size = 18  # @param {type:\"slider\", min:1, max:64, step:1}\n",
    "# reaching ~10GB GPU Memory Peaks\n",
    "\n",
    "# @markdown Choose number of threads (ignored if CUDA/GPU availible)\n",
    "threads = 8  # @param {type:\"slider\", min:1, max:16, step:1}\n",
    "\n",
    "if download_embeddings and encoding_model_name == \"Rostlab/prot_t5_xl_uniref50\":\n",
    "\n",
    "    print(\"Downloading preprocessed prot_t5_xl_uniref50 embeddings.\")\n",
    "    !wget {_encodings_download_url} -O dataset.zip\n",
    "    !unzip -q dataset.zip -d {_encodings_output_dir}\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Generating Embeddings\")\n",
    "\n",
    "    if not _list_files(_fasta_input_dir):\n",
    "        raise FileNotFoundError(\"Input directory is empty or does not exist.\")\n",
    "\n",
    "    try:\n",
    "        await generate_embeddings(\n",
    "            model_name = encoding_model_name,\n",
    "            input_dir = _fasta_input_dir,\n",
    "            output_dir = _encodings_output_dir,\n",
    "            batch_size = batch_size,\n",
    "            threads = threads\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Error during encoding generation:\")\n",
    "        print(str(e))\n",
    "        terminate = True\n",
    "\n",
    "    time.sleep(60)  # \"Wait a minute.\" - Kazoo Kid\n",
    "    # Prematurely terminating would make some file transfers to drive incomplete.\n",
    "\n",
    "print(f\"Contents of '{_encodings_output_dir}':\")\n",
    "_list_files(_encodings_output_dir)\n",
    "\n",
    "__cell4 = True"
   ],
   "id": "776552ed2d0da0a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"5-visualize-data\"></a>\n",
    "### 5. Visualize Data\n",
    "#### [←](#4-create-encodings-must-execute) [↑](#table-of-contents) [→](#6-train-model)"
   ],
   "id": "16b6bb4f10740174"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell4' in globals(), \"You must execute cell 4 before!\"\n",
    "\n",
    "from source.data_scripts.data_figures import DataFiguresCollection, PoolingType\n",
    "from source.data_scripts.encodings import load_metadata_from_hdf5, stream_seq_enc_data_from_hdf5\n",
    "\n",
    "\n",
    "if not _list_files(_encodings_output_dir):\n",
    "    raise FileNotFoundError(\"Input directory is empty or does not exist.\")\n",
    "\n",
    "\n",
    "__figures: DataFiguresCollection = DataFiguresCollection(save_dir=_figures_save_dir)\n",
    "__figures.class_distribution()\n",
    "__figures.pca_embedding(pooling_type=PoolingType.Per_Protein_Mean)\n",
    "__figures.tsne_embedding(pooling_type=PoolingType.Per_Protein_Mean)\n",
    "__figures.umap_embedding(pooling_type=PoolingType.Per_Protein_Mean)\n",
    "__figures.pca_embedding(pooling_type=PoolingType.Per_Protein_Max)\n",
    "__figures.tsne_embedding(pooling_type=PoolingType.Per_Protein_Max)\n",
    "__figures.umap_embedding(pooling_type=PoolingType.Per_Protein_Max)\n",
    "__figures.raw_sequence_length_distribution(bins=150, log_y=False)\n",
    "__figures.embedding_length_distribution(bins=150, log_y=False)\n",
    "__figures.embedding_length_distribution(bins=150, log_y=True)\n",
    "# __figures.pairwise_distance_distribution(bins=150, distance_metric=\"euclidean\", pooling_type=__pooling_type)\n",
    "# Simply too many pairwise comparisons resulting in too many values for the figure to handle...\n",
    "\n",
    "\n",
    "for __file_name, __file_path in [\n",
    "    (train_file_name, _train_encodings_file_path),\n",
    "    (val_file_name,   _val_encodings_file_path),\n",
    "    (test_file_name,  _test_encodings_file_path),\n",
    "    (\"Aggregated\", [_train_encodings_file_path, _val_encodings_file_path, _test_encodings_file_path])\n",
    "]:\n",
    "\n",
    "    __encoding_dim, __count, __label_count = load_metadata_from_hdf5(file_path=__file_path)\n",
    "    __seq_enc_data_generator_supplier = lambda: stream_seq_enc_data_from_hdf5(file_path=__file_path)\n",
    "\n",
    "    __identifier = f\"{encoding_model_name}_{__file_name}\"\n",
    "\n",
    "    __figures.update(\n",
    "        identifier = __identifier.replace(\"/\", \"_\"),\n",
    "        label_count = __label_count,\n",
    "        seq_enc_data_generator_supplier = __seq_enc_data_generator_supplier,\n",
    "        file_name = __file_name,\n",
    "        encoding_model = encoding_model_name,\n",
    "    )\n",
    "\n",
    "    __figures.save(\"data_visualization\")\n",
    "\n",
    "    print(f\"{__identifier}\")\n",
    "    print(f\"Encoding dimension: {__encoding_dim}\")\n",
    "    print(f\"Number of sequences: {__count}\")\n",
    "\n",
    "del __figures"
   ],
   "id": "defbf9447eaff282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"6-train-model\"></a>\n",
    "### 6. Train Model\n",
    "#### [←](#5-visualize-data) [↑](#table-of-contents) [→](#7-continue-training-a-saved-model)"
   ],
   "id": "ee80078a82cda2b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell4' in globals(), \"You must execute cell 4 before!\"\n",
    "\n",
    "from source.models.abstract import AbstractModel\n",
    "from source.models.ffn import MLP, MLPpp, FastKAN\n",
    "from source.config import AbstractTrainingConfig, HyperParamConfig, ConfigType, parse_config\n",
    "from source.models.other.attention_lstm_hybrid import AttentionLstmHybridFastKAN\n",
    "from source.models.other.lstm_reduction_hybrid import LstmAttentionReductionHybridFastKAN\n",
    "from source.models.other.light_attention import (\n",
    "    LightAttention,\n",
    "    LightAttentionFastKAN,\n",
    ")\n",
    "from source.models.reduced_ffn import (\n",
    "    MaxPoolFastKAN,\n",
    "    MaxPoolMLP,\n",
    "    AvgPoolFastKAN,\n",
    "    AvgPoolMLP,\n",
    "    LinearFastKAN,\n",
    "    LinearMLP,\n",
    "    AttentionFastKAN,\n",
    "    AttentionMLP,\n",
    "    PositionalFastKAN,\n",
    "    PositionalMLP,\n",
    "    UNetFastKAN,\n",
    "    UNetMLP\n",
    ")\n",
    "\n",
    "\n",
    "__model_name_to_class: dict[str, AbstractModel] = {\n",
    "    \"MLP\": MLP,\n",
    "    \"MLP_PerProtein\": MLPpp,\n",
    "    \"FastKAN\": FastKAN,\n",
    "\n",
    "    \"LightAttention\": LightAttention,\n",
    "    \"LightAttentionFastKAN\": LightAttentionFastKAN,\n",
    "\n",
    "    \"MaxPoolFastKAN\": MaxPoolFastKAN,\n",
    "    \"MaxPoolMLP\": MaxPoolMLP,\n",
    "    \"AvgPoolFastKAN\": AvgPoolFastKAN,\n",
    "    \"AvgPoolMLP\": AvgPoolMLP,\n",
    "    \"LinearFastKAN\": LinearFastKAN,\n",
    "    \"LinearMLP\": LinearMLP,\n",
    "    \"AttentionFastKAN\": AttentionFastKAN,\n",
    "    \"AttentionMLP\": AttentionMLP,\n",
    "    \"PosFastKAN\": PositionalFastKAN,\n",
    "    \"PosMLP\": PositionalMLP,\n",
    "    \"UNetFastKAN\": UNetFastKAN,\n",
    "    \"UNetMLP\": UNetMLP,\n",
    "\n",
    "    \"AttentionLstmHybridFastKAN\": AttentionLstmHybridFastKAN,\n",
    "    \"LstmAttentionReductionHybridFastKAN\": LstmAttentionReductionHybridFastKAN\n",
    "}\n",
    "\n",
    "# @ Select Model to train (adjust parameters in config.yaml):\n",
    "model_name = \"AttentionFastKAN\"  # @param [\"MLP\", \"MLP_PerProtein\", \"FastKAN\", \"MaxPoolFastKAN\", \"MaxPoolMLP\", \"AvgPoolFastKAN\", \"AvgPoolMLP\", \"LinearFastKAN\", \"LinearMLP\", \"AttentionFastKAN\", \"AttentionMLP\", \"PosFastKAN\", \"PosMLP\", \"UNetFastKAN\", \"UNetMLP\", \"AttentionLstmHybrid\", \"LstmReductionHybrid\", \"LightAttention\", \"LightAttentionFastKAN\"]\n",
    "\n",
    "use_config_defaults = False  # @param {type:\"boolean\"}\n",
    "\n",
    "epochs = 50  # @param {type:\"slider\", min:1, max:100, step:1}\n",
    "patience = 20  # @param {type:\"slider\", min:1, max:20, step:1}\n",
    "batch_size = 28  # @param {type:\"slider\", min:1, max:64, step:1}\n",
    "\n",
    "learning_rate = 0.00005  # @param [\"0.001\", \"0.0005\", \"0.0001\", \"0.00005\"] {\"type\":\"raw\"}\n",
    "learning_rate_decay = 0.98  # @param [\"0.80\", \"0.85\", \"0.90\", \"0.925\", \"0.95\", \"0.96\", \"0.97\", \"0.98\", \"0.99\", \"0.995\", \"1.0\"] {\"type\":\"raw\"}\n",
    "l2_penalty = 0.0  # @param [\"0.0\", \"0.001\", \"0.0005\", \"0.0001\", \"0.00005\", \"0.00001\"] {\"type\":\"raw\"}\n",
    "weight_factor = 0.00  # @param {type:\"slider\", min:0.00, max:1.00, step:0.05}\n",
    "\n",
    "# @markdown Select if you want to perform a hyperparameter search or just train the model:\n",
    "do_hyper_param_search = False  # @param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "if not _list_files(_encodings_output_dir):\n",
    "    raise FileNotFoundError(f\"Encodings directory {_encodings_output_dir} is empty or does not exist.\")\n",
    "\n",
    "__model_class = __model_name_to_class[model_name]\n",
    "\n",
    "if use_config_defaults:\n",
    "    training_config: AbstractTrainingConfig = parse_config(ConfigType.HyperParam) if do_hyper_param_search else parse_config(ConfigType.Training)\n",
    "    epochs = training_config.epochs\n",
    "    patience = training_config.patience\n",
    "    batch_size = training_config.batch_size\n",
    "    learning_rate = training_config.learning_rate\n",
    "    learning_rate_decay = training_config.learning_rate_decay\n",
    "    l2_penalty = training_config.l2_penalty\n",
    "    weight_factor = training_config.weight_factor\n",
    "    print(f\"Loaded parameters: epochs={epochs}, patience={patience}, batch_size={batch_size}, learning_rate={learning_rate}, learning_rate_decay={learning_rate_decay}, l2_penalty={l2_penalty}, weight_factor={weight_factor}\")\n",
    "else:\n",
    "    print(f\"Using manually defined parameters: epochs={epochs}, patience={patience}, batch_size={batch_size}, learning_rate={learning_rate}, learning_rate_decay={learning_rate_decay}, l2_penalty={l2_penalty}, weight_factor={weight_factor}\")\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    if do_hyper_param_search:\n",
    "        from source.training.hyper_param import main as tune\n",
    "        hyper_param_config: HyperParamConfig = parse_config(ConfigType.HyperParam)\n",
    "\n",
    "        __n_trials = hyper_param_config.n_trials\n",
    "        __timeout = hyper_param_config.timeout\n",
    "\n",
    "        tune(\n",
    "            model_class = __model_class,\n",
    "            train_encodings_file_path = _train_encodings_file_path,\n",
    "            val_encodings_file_path = _val_encodings_file_path,\n",
    "            epochs = epochs,\n",
    "            patience = patience,\n",
    "            batch_size = batch_size,\n",
    "            l2_penalty = l2_penalty,\n",
    "            weight_factor = weight_factor,\n",
    "            learning_rate = learning_rate,\n",
    "            learning_rate_decay = learning_rate_decay,\n",
    "            n_trials = __n_trials,\n",
    "            timeout = __timeout,\n",
    "            study_name = __model_class.name(),\n",
    "            studies_save_dir = _studies_save_dir,\n",
    "            model_save_dir = _model_save_dir,\n",
    "            figures_save_dir = _figures_save_dir,\n",
    "            metrics_file_path= _hyper_param_metrics_file_path,\n",
    "            log_file_path = _log_file_path\n",
    "        )\n",
    "        _list_files(f\"{_model_save_dir}/hyper_param\")\n",
    "\n",
    "    else:\n",
    "        from source.training.train_model import main as train\n",
    "\n",
    "        train(\n",
    "            model = __model_class,\n",
    "            train_encodings_file_path = _train_encodings_file_path,\n",
    "            val_encodings_file_path = _val_encodings_file_path,\n",
    "            epochs = epochs,\n",
    "            patience = patience,\n",
    "            batch_size = batch_size,\n",
    "            l2_penalty = l2_penalty,\n",
    "            weight_factor = weight_factor,\n",
    "            learning_rate = learning_rate,\n",
    "            learning_rate_decay = learning_rate_decay,\n",
    "            model_save_dir = _model_save_dir,\n",
    "            figures_save_dir = _figures_save_dir,\n",
    "            metrics_file_path= _training_metrics_file_path,\n",
    "            log_file_path = _log_file_path\n",
    "        )\n",
    "        _list_files(f\"{_model_save_dir}/training\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\")\n",
    "    print(str(e))\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ],
   "id": "a6ce17bbd471ea70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"7-continue-training-a-saved-model\"></a>\n",
    "### 7. Continue Training a Saved Model\n",
    "#### [←](#6-train-model) [↑](#table-of-contents) [→](#8-model-comparison)"
   ],
   "id": "a5e742b8cf721746"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell4' in globals(), \"You must execute cell 4 before!\"\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from source.training.train_model import main as train\n",
    "\n",
    "\n",
    "use_config_defaults = True  # @param {type:\"boolean\"}\n",
    "epochs = 100  # @param {type:\"slider\", min:1, max:250, step:1}\n",
    "# consider higher patience. Sometimes model recalibrate themselves after overfitting on epoch 3\n",
    "patience = 20  # @param {type:\"slider\", min:1, max:50, step:1}\n",
    "batch_size = 28  # @param {type:\"slider\", min:1, max:64, step:1}\n",
    "\n",
    "learning_rate = 0.00005  # @param [\"0.001\", \"0.005\", \"0.001\", \"0.0005\", \"0.0001\", \"0.00005\"] {\"type\":\"raw\"}\n",
    "learning_rate_decay = 0.98  # @param [\"0.80\", \"0.85\", \"0.90\", \"0.95\", \"0.98\", \"0.99\"] {\"type\":\"raw\"}\n",
    "\n",
    "# Testing if models can be improved by continuing to train with class weights.\n",
    "l2_penalty = 0.0001  # @param [\"0.0\", \"0.001\", \"0.0005\", \"0.0001\", \"0.00005\", \"0.00001\"] {\"type\":\"raw\"}\n",
    "weight_factor = 0.5  # @param {type:\"slider\", min:0.00, max:1.00, step:0.05}\n",
    "\n",
    "\n",
    "if use_config_defaults:\n",
    "    from source.config import TrainingConfig, ConfigType, parse_config\n",
    "    training_config: TrainingConfig = parse_config(ConfigType.Training)\n",
    "    epochs = training_config.epochs\n",
    "    patience = training_config.patience\n",
    "    batch_size = training_config.batch_size\n",
    "    learning_rate = training_config.learning_rate\n",
    "    learning_rate_decay = training_config.learning_rate_decay\n",
    "    l2_penalty = training_config.l2_penalty\n",
    "    weight_factor = training_config.weight_factor\n",
    "    print(f\"Loaded parameters: epochs={epochs}, patience={patience}, batch_size={batch_size}, learning_rate={learning_rate}, learning_rate_decay={learning_rate_decay}, l2_penalty={l2_penalty}, weight_factor={weight_factor}\")\n",
    "else:\n",
    "    print(f\"Using manually defined parameters: epochs={epochs}, patience={patience}, batch_size={batch_size}, learning_rate={learning_rate}, learning_rate_decay={learning_rate_decay}, l2_penalty={l2_penalty}, weight_factor={weight_factor}\")\n",
    "\n",
    "\n",
    "__files = _list_files(_model_save_dir)\n",
    "# __files.sort()\n",
    "if not __files: raise FileNotFoundError(f\"Model save directory {_model_save_dir} is empty or does not exist.\")\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def wait_for_click(button: widgets.Button) -> asyncio.Future:\n",
    "    future = asyncio.Future()\n",
    "\n",
    "    def on_click(_):\n",
    "        future.set_result(True)\n",
    "        button.on_click(on_click, remove=True)\n",
    "\n",
    "    button.on_click(on_click)\n",
    "    return future\n",
    "\n",
    "# TODO: Code below runs into an deadlock.\n",
    "# UI starts a different thread but the main thread is blocking the execution.\n",
    "# But if the main thread is finished, then the button can execute the function.\n",
    "# Because google colab thinks that the cell is idle (main thread is finished) the runtime gets disconnected after some time.\n",
    "async def run_continue_training():\n",
    "\n",
    "    __dropdown = widgets.Dropdown(\n",
    "        options = __files,\n",
    "        description = 'Select:',\n",
    "        value = None\n",
    "    )\n",
    "    __button = widgets.Button(description=\"Continue\")\n",
    "\n",
    "    display(widgets.VBox([__dropdown, __button]))\n",
    "\n",
    "    await wait_for_click(__button)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if __selected_filename := __dropdown.value:\n",
    "        print(f\"Model selected: {__selected_filename}\")\n",
    "\n",
    "        try:\n",
    "            train(\n",
    "                model = os.path.join(_model_save_dir, __selected_filename),\n",
    "                train_encodings_file_path = _train_encodings_file_path,\n",
    "                val_encodings_file_path = _val_encodings_file_path,\n",
    "                epochs = epochs,\n",
    "                patience = patience,\n",
    "                batch_size = batch_size,\n",
    "                l2_penalty = l2_penalty,\n",
    "                weight_factor = weight_factor,\n",
    "                learning_rate = learning_rate,\n",
    "                learning_rate_decay = learning_rate_decay,\n",
    "                model_save_dir = _model_save_dir,\n",
    "                figures_save_dir = _figures_save_dir,\n",
    "                metrics_file_path = _training_metrics_file_path,\n",
    "                log_file_path = _log_file_path\n",
    "            )\n",
    "            _list_files(f\"{_model_save_dir}/training\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error during continued training:\")\n",
    "            print(str(e))\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    else:\n",
    "        print(\"No model was selected. Halting execution.\")\n",
    "\n",
    "\n",
    "await run_continue_training()"
   ],
   "id": "a09c38739cd7d27e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"8-model-comparison\"></a>\n",
    "### 8. Model Comparison\n",
    "#### [←](#7-continue-training-a-saved-model) [↑](#table-of-contents) [→](#9-explore-figures)"
   ],
   "id": "2dc86ce86d673a2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell4' in globals(), \"You must execute cell 4 before!\"\n",
    "\n",
    "%gui asyncio\n",
    "\n",
    "# import ipywidgets as widgets\n",
    "from typing_extensions import List\n",
    "# from IPython.display import display, clear_output\n",
    "\n",
    "from source.evaluation.evaluation import main as evaluate\n",
    "\n",
    "\n",
    "iterations = 100  # @param {type:\"slider\", min:10, max:500, step:10}\n",
    "batch_size = 28  # @param {type:\"slider\", min:1, max:64, step:1}\n",
    "\n",
    "# using only final trained models\n",
    "__training_model_save_dir = os.path.join(_model_save_dir, \"training\")\n",
    "__model_file_names: List[str] = _list_files(__training_model_save_dir)\n",
    "if not __model_file_names:\n",
    "    raise FileNotFoundError(f\"No models found in directory: {__training_model_save_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "__model_file_paths = [\n",
    "    os.path.join(__training_model_save_dir, model_file_name)\n",
    "    for model_file_name in __model_file_names\n",
    "]\n",
    "\n",
    "for model_file_path in __model_file_paths:\n",
    "    print(f\"  - {os.path.basename(model_file_path)}\")\n",
    "\n",
    "evaluate(\n",
    "    model_file_paths = __model_file_paths,\n",
    "    test_encodings_file_path = _test_encodings_file_path,\n",
    "    figures_save_dir = _figures_save_dir,\n",
    "    iterations = iterations,\n",
    "    batch_size = batch_size,\n",
    "    metrics_file_path = _evaluation_metrics_file_path,\n",
    "    log_file_path = _log_file_path\n",
    ")\n",
    "\n",
    "# TODO: Code below runs into an deadlock. (Same problem as above)\n",
    "# async def run_model_comparison():\n",
    "#\n",
    "#     __selection = widgets.SelectMultiple(\n",
    "#         options = __model_file_names,\n",
    "#         value = tuple(__model_file_names),  # pre-select all\n",
    "#         description = 'Models',\n",
    "#         disabled = False,\n",
    "#         layout = widgets.Layout(width='100%')\n",
    "#     )\n",
    "#\n",
    "#     __button = widgets.Button(description=\"Load Selected Models\")\n",
    "#\n",
    "#     display(widgets.VBox([__selection, __button]))\n",
    "#\n",
    "#     await wait_for_click(__button)\n",
    "#\n",
    "#     clear_output(wait=True)\n",
    "#\n",
    "#     try:\n",
    "#         __model_file_paths = [\n",
    "#             os.path.join(__training_model_save_dir, model_file_name)\n",
    "#             for model_file_name in __selection.value\n",
    "#         ]\n",
    "#\n",
    "#         if __model_file_paths:\n",
    "#             print(\"Model selected:\")\n",
    "#             for model_file_path in __model_file_paths: print(f\"  - {os.path.basename(model_file_path)}\")\n",
    "#             evaluate(\n",
    "#                 model_file_paths = __model_file_paths,\n",
    "#                 test_encodings_file_path = _test_encodings_file_path,\n",
    "#                 figures_save_dir = _figures_save_dir,\n",
    "#                 iterations = iterations,\n",
    "#                 batch_size = batch_size\n",
    "#             )\n",
    "#             print(\"\\nEvaluation Finished Successfully\")\n",
    "#         else:\n",
    "#             print(\"No models selected. Please select at least one model.\")\n",
    "#\n",
    "#     except Exception as e:\n",
    "#         print(\"Error during model comparison:\")\n",
    "#         print(str(e))\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#\n",
    "#\n",
    "# await run_model_comparison()"
   ],
   "id": "5b003911e1661d40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"9-explore-figures\"></a>\n",
    "### 9. Explore Figures\n",
    "#### [←](#8-model-comparison) [↑](#table-of-contents)"
   ],
   "id": "df2d4192df8488f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert '__cell4' in globals(), \"You must execute cell 4 before!\"\n",
    "\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing_extensions import List, Dict, Tuple\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from source.abstract_figures import ViewFiguresCollection\n",
    "\n",
    "\n",
    "# Data Aggregation: Scan all subdirectories of the main figures directory\n",
    "# Structure: { \"SubdirectoryName\": [(\"display_label\", \"full/path/to/figure.pkl\"), ...]}\n",
    "figures_by_subdir: Dict[str, List[Tuple[str, str]]] = defaultdict(list)\n",
    "pdfs_by_subdir: Dict[str, List[Tuple[str, str]]] = defaultdict(list)\n",
    "\n",
    "for subdir_name in sorted(os.listdir(_figures_save_dir)):\n",
    "    subdir_path = os.path.join(_figures_save_dir, subdir_name)\n",
    "    if not os.path.isdir(subdir_path): continue\n",
    "\n",
    "    # Recursively find all .pkl files within this subdirectory\n",
    "    for dirpath, _, filenames in os.walk(subdir_path):\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            display_label = os.path.relpath(full_path, subdir_path)\n",
    "            # Create a user-friendly label showing the path relative to the tab's directory\n",
    "            if filename.lower().endswith(\".pkl\"):\n",
    "                figures_by_subdir[subdir_name].append((display_label, full_path))\n",
    "            elif filename.lower().endswith(\".pdf\"):\n",
    "                pdfs_by_subdir[subdir_name].append((display_label, full_path))\n",
    "\n",
    "if not figures_by_subdir and not pdfs_by_subdir:\n",
    "    raise FileNotFoundError(f\"No .pkl or .pdf files found in any subdirectories of '{_figures_save_dir}'\")\n",
    "\n",
    "\n",
    "# Build the figures accordion\n",
    "pkl_accordion_children = []\n",
    "pkl_accordion_titles = []\n",
    "\n",
    "# Create a widget for each subdirectory that contains figures\n",
    "for subdir_name, files in figures_by_subdir.items():\n",
    "    # Sort files within each group for a consistent order\n",
    "    sorted_files = sorted(files, key=lambda item: item[0])\n",
    "\n",
    "    file_selector = widgets.SelectMultiple(\n",
    "        options = sorted_files,\n",
    "        description = ' ', # An empty description looks cleaner\n",
    "        disabled = False,\n",
    "        layout = widgets.Layout(width='95%', height='200px')\n",
    "    )\n",
    "    pkl_accordion_children.append(file_selector)\n",
    "    pkl_accordion_titles.append(subdir_name)\n",
    "\n",
    "# Create the accordion widget itself\n",
    "pkl_accordion = widgets.Accordion(children=pkl_accordion_children)\n",
    "for i, title in enumerate(pkl_accordion_titles):\n",
    "    pkl_accordion.set_title(i, title)\n",
    "\n",
    "\n",
    "pdf_accordion_children = []\n",
    "pdf_accordion_titles = []\n",
    "\n",
    "for subdir_name, files in pdfs_by_subdir.items():\n",
    "    sorted_files = sorted(files, key=lambda item: item[0])\n",
    "    file_selector = widgets.SelectMultiple(\n",
    "        options = sorted_files,\n",
    "        description = ' ',\n",
    "        disabled = False,\n",
    "        layout = widgets.Layout(width='95%', height='150px')\n",
    "    )\n",
    "    pdf_accordion_children.append(file_selector)\n",
    "    pdf_accordion_titles.append(f\"{subdir_name} Reports\")\n",
    "\n",
    "pdf_accordion = widgets.Accordion(children=pdf_accordion_children)\n",
    "for i, title in enumerate(pdf_accordion_titles):\n",
    "    pdf_accordion.set_title(i, title)\n",
    "\n",
    "load_button = widgets.Button(description=\"Load Selected\")\n",
    "\n",
    "\n",
    "def on_button_clicked(_):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Figures\n",
    "    figures = ViewFiguresCollection()  # Re-init to clear old figures\n",
    "    all_selected_figure_paths = []\n",
    "\n",
    "    # Iterate through all  the SelectMultiple widgets in the accordion\n",
    "    for child_widget in pkl_accordion.children:\n",
    "        # child_widget.value is a tuple of the full paths selected in that box\n",
    "        all_selected_figure_paths.extend(child_widget.value)\n",
    "\n",
    "    if all_selected_figure_paths:\n",
    "        for full_path in all_selected_figure_paths: figures.load(full_path)\n",
    "        print(f\"Loaded and displayed {len(all_selected_figure_paths)} figures.\")\n",
    "        figures.display(clear=False)\n",
    "\n",
    "    # PDFs\n",
    "    all_selected_pdf_paths = []\n",
    "\n",
    "    for child_widget in pdf_accordion.children:\n",
    "        all_selected_pdf_paths.extend(child_widget.value)\n",
    "\n",
    "    if all_selected_pdf_paths:\n",
    "        print(f\"\\nDisplaying {len(all_selected_pdf_paths)} PDF reports:\")\n",
    "        pdf_widgets_to_display = []\n",
    "\n",
    "        for full_path in all_selected_pdf_paths:\n",
    "\n",
    "            try:\n",
    "                display_label = os.path.relpath(full_path, _figures_save_dir)\n",
    "                title_widget = widgets.HTML(f\"<h4>--- {display_label} ---</h4>\")\n",
    "\n",
    "                # IFrame will route the view to localhost:8080 for the file. Thats why we have to load it.\n",
    "                with open(full_path, \"rb\") as f: pdf_bytes = f.read()\n",
    "                base64_pdf = base64.b64encode(pdf_bytes).decode('utf-8')\n",
    "                pdf_data_uri = f\"data:application/pdf;base64,{base64_pdf}\"\n",
    "\n",
    "                # multiple pdfs need can be loaded as html widgets.\n",
    "                iframe_html = f\"<iframe src='{pdf_data_uri}' width='100%' height='600'></iframe>\"\n",
    "                html_widget = widgets.HTML(value=iframe_html)\n",
    "\n",
    "                pdf_widgets_to_display.append(title_widget)\n",
    "                pdf_widgets_to_display.append(html_widget)\n",
    "\n",
    "            except Exception as error:\n",
    "                pdf_widgets_to_display.append(widgets.HTML(f\"<p style='color:red;'>Error displaying PDF {full_path}: {error}</p>\"))\n",
    "\n",
    "        pdf_container = widgets.VBox(pdf_widgets_to_display)\n",
    "        display(pdf_container)\n",
    "\n",
    "    if not all_selected_figure_paths and not all_selected_pdf_paths: print(\"No items selected.\")\n",
    "\n",
    "\n",
    "load_button.on_click(on_button_clicked)\n",
    "\n",
    "\n",
    "# Display the UI\n",
    "ui_elements = []\n",
    "if figures_by_subdir:\n",
    "    ui_elements.append(widgets.HTML(\"<h3>Figure Selector (.pkl)</h3>\"))\n",
    "    ui_elements.append(pkl_accordion)\n",
    "if pdfs_by_subdir:\n",
    "    ui_elements.append(widgets.HTML(\"<h3>Report Selector (.pdf)</h3>\"))\n",
    "    ui_elements.append(pdf_accordion)\n",
    "ui_elements.append(load_button)\n",
    "display(widgets.VBox(ui_elements))"
   ],
   "id": "2419bd55fe9e7e56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run this cell below to automatically stop the colab runtime.<br>",
   "id": "4ec9601e159e6023"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ],
   "id": "a4ddcc6f60740852"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
